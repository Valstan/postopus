#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ MongoDB –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostOpus.
"""
import json
import logging
from datetime import datetime
from typing import Dict, Any, List, Set
from collections import Counter, defaultdict
from pymongo import MongoClient
from pymongo.errors import ConnectionFailure
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MongoAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ MongoDB –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    
    def __init__(self, mongo_url: str):
        self.mongo_url = mongo_url
        self.client = None
        self.db = None
        self.analysis_results = {}
        
    def connect(self) -> bool:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB."""
        try:
            self.client = MongoClient(self.mongo_url)
            self.db = self.client['postopus']
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            self.client.admin.command('ping')
            logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MongoDB —É—Å–ø–µ—à–Ω–æ")
            return True
        except ConnectionFailure as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MongoDB: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏: {e}")
            return False
    
    def analyze_collections(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."""
        logger.info("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏...")
        
        collections = self.db.list_collection_names()
        logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ –∫–æ–ª–ª–µ–∫—Ü–∏–π: {len(collections)}")
        
        collection_analysis = {}
        
        for collection_name in collections:
            logger.info(f"üìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é: {collection_name}")
            
            collection = self.db[collection_name]
            
            # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            doc_count = collection.count_documents({})
            
            # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            sample_docs = list(collection.find().limit(10))
            field_analysis = self._analyze_document_structure(sample_docs)
            
            # –ê–Ω–∞–ª–∏–∑ –∏–Ω–¥–µ–∫—Å–æ–≤
            indexes = list(collection.list_indexes())
            
            collection_analysis[collection_name] = {
                'document_count': doc_count,
                'sample_documents': sample_docs,
                'field_analysis': field_analysis,
                'indexes': indexes,
                'is_empty': doc_count == 0
            }
            
            logger.info(f"  üìä –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_count}")
            logger.info(f"  üîë –ü–æ–ª—è: {list(field_analysis.keys())}")
        
        return collection_analysis
    
    def _analyze_document_structure(self, documents: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        if not documents:
            return {}
        
        field_types = defaultdict(set)
        field_values = defaultdict(list)
        field_counts = defaultdict(int)
        
        for doc in documents:
            for field, value in doc.items():
                field_types[field].add(type(value).__name__)
                field_counts[field] += 1
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –∑–Ω–∞—á–µ–Ω–∏–π (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)
                if isinstance(value, (str, int, float, bool)) and len(str(value)) < 100:
                    field_values[field].append(value)
                elif isinstance(value, dict) and len(str(value)) < 200:
                    field_values[field].append(value)
                elif isinstance(value, list) and len(value) < 10:
                    field_values[field].append(value)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –ø–æ–ª–µ–π
        field_analysis = {}
        for field, types in field_types.items():
            field_analysis[field] = {
                'types': list(types),
                'count': field_counts[field],
                'sample_values': field_values[field][:5],  # –ü–µ—Ä–≤—ã–µ 5 –ø—Ä–∏–º–µ—Ä–æ–≤
                'is_optional': field_counts[field] < len(documents)
            }
        
        return field_analysis
    
    def analyze_posts_data(self) -> Dict[str, Any]:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤."""
        logger.info("üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç–æ–≤...")
        
        posts_analysis = {
            'collections_with_posts': [],
            'total_posts': 0,
            'post_types': Counter(),
            'platforms': Counter(),
            'statuses': Counter(),
            'date_ranges': {},
            'content_analysis': {}
        }
        
        # –ò—â–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å –ø–æ—Å—Ç–∞–º–∏
        collections = self.db.list_collection_names()
        post_collections = [col for col in collections if col not in [
            'users', 'settings', 'logs', 'statistics', 'health_checks', 
            'task_executions', 'tasks', 'config', 'deserter', 'bal'
        ]]
        
        posts_analysis['collections_with_posts'] = post_collections
        
        for collection_name in post_collections:
            collection = self.db[collection_name]
            doc_count = collection.count_documents({})
            posts_analysis['total_posts'] += doc_count
            
            logger.info(f"  üìÑ {collection_name}: {doc_count} –ø–æ—Å—Ç–æ–≤")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ—Å—Ç–æ–≤
            sample_posts = list(collection.find().limit(50))
            
            for post in sample_posts:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                if 'image' in post or 'image_url' in post:
                    posts_analysis['post_types']['with_image'] += 1
                if 'video' in post or 'video_url' in post:
                    posts_analysis['post_types']['with_video'] += 1
                if 'text' in post or 'content' in post:
                    posts_analysis['post_types']['with_text'] += 1
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
                if 'vk_group_id' in post or 'group_id' in post:
                    posts_analysis['platforms']['vk'] += 1
                if 'telegram_chat_id' in post:
                    posts_analysis['platforms']['telegram'] += 1
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å—ã
                status = post.get('status', 'unknown')
                posts_analysis['statuses'][status] += 1
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞—Ç—ã
                created_at = post.get('created_at')
                if created_at:
                    if collection_name not in posts_analysis['date_ranges']:
                        posts_analysis['date_ranges'][collection_name] = {
                            'earliest': created_at,
                            'latest': created_at
                        }
                    else:
                        if created_at < posts_analysis['date_ranges'][collection_name]['earliest']:
                            posts_analysis['date_ranges'][collection_name]['earliest'] = created_at
                        if created_at > posts_analysis['date_ranges'][collection_name]['latest']:
                            posts_analysis['date_ranges'][collection_name]['latest'] = created_at
        
        return posts_analysis
    
    def analyze_config_data(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        logger.info("‚öôÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
        
        config_analysis = {
            'config_documents': {},
            'groups': {},
            'users': {},
            'tasks': {},
            'settings': {}
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é config
        config_collection = self.db['config']
        config_docs = list(config_collection.find({}))
        
        for doc in config_docs:
            doc_title = doc.get('title', 'unknown')
            config_analysis['config_documents'][doc_title] = {
                'keys': list(doc.keys()),
                'has_groups': 'all_my_groups' in doc,
                'has_filters': any(key in doc for key in ['delete_msg_blacklist', 'clear_text_blacklist', 'black_id']),
                'document_size': len(str(doc))
            }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—ã
            if 'all_my_groups' in doc:
                groups = doc['all_my_groups']
                config_analysis['groups'] = {
                    'count': len(groups),
                    'groups': groups,
                    'platforms': list(set(str(gid)[0] if str(gid).startswith('-') else 'positive' for gid in groups.values()))
                }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        users_collection = self.db['users']
        users = list(users_collection.find({}))
        config_analysis['users'] = {
            'count': len(users),
            'users': [{'username': u.get('username'), 'email': u.get('email'), 'is_admin': u.get('is_admin', False)} for u in users]
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏
        tasks_collection = self.db['tasks']
        tasks = list(tasks_collection.find({}))
        config_analysis['tasks'] = {
            'count': len(tasks),
            'enabled_tasks': len([t for t in tasks if t.get('enabled', False)]),
            'task_types': list(set(t.get('type', 'unknown') for t in tasks))
        }
        
        return config_analysis
    
    def generate_migration_plan(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞."""
        logger.info("üìã –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏...")
        
        migration_plan = {
            'priority_collections': [],
            'data_mapping': {},
            'recommendations': [],
            'potential_issues': [],
            'estimated_workload': {}
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collections = self.analysis_results.get('collections', {})
        
        for collection_name, analysis in collections.items():
            if analysis['document_count'] > 0:
                if collection_name in ['users', 'config']:
                    migration_plan['priority_collections'].append({
                        'name': collection_name,
                        'priority': 'high',
                        'reason': '–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'
                    })
                elif collection_name not in ['logs', 'statistics', 'health_checks']:
                    migration_plan['priority_collections'].append({
                        'name': collection_name,
                        'priority': 'medium',
                        'reason': '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ'
                    })
        
        # –ü–ª–∞–Ω–∏—Ä—É–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
        migration_plan['data_mapping'] = {
            'posts': {
                'source_collections': [col for col in collections.keys() if col not in ['users', 'config', 'logs', 'statistics', 'health_checks', 'task_executions', 'tasks', 'deserter', 'bal']],
                'target_table': 'posts',
                'strategy': 'merge_all_collections'
            },
            'groups': {
                'source_collections': ['config'],
                'target_table': 'groups',
                'strategy': 'extract_from_config'
            },
            'users': {
                'source_collections': ['users'],
                'target_table': 'users',
                'strategy': 'direct_mapping'
            },
            'schedules': {
                'source_collections': ['tasks'],
                'target_table': 'schedules',
                'strategy': 'direct_mapping'
            }
        }
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        migration_plan['recommendations'] = [
            "–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é MongoDB –ø–µ—Ä–µ–¥ –º–∏–≥—Ä–∞—Ü–∏–µ–π",
            "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é –Ω–∞ –∫–æ–ø–∏–∏ –¥–∞–Ω–Ω—ã—Ö",
            "–î–æ–±–∞–≤–∏—Ç—å –ø–æ–ª–µ source_collection –≤ —Ç–∞–±–ª–∏—Ü—É posts –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞",
            "–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –ø–æ–ª–µ–π",
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è admin –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –Ω–µ—Ç"
        ]
        
        return migration_plan
    
    def save_analysis_report(self, output_file: str = "mongo_analysis_report.json"):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞."""
        logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ {output_file}")
        
        report = {
            'analysis_timestamp': datetime.now().isoformat(),
            'database_url': self.mongo_url.replace(self.mongo_url.split('@')[0].split('//')[1].split(':')[0], '***'),
            'analysis_results': self.analysis_results
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
    
    def run_full_analysis(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ MongoDB –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        if not self.connect():
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MongoDB")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        self.analysis_results['collections'] = self.analyze_collections()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã
        self.analysis_results['posts_analysis'] = self.analyze_posts_data()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.analysis_results['config_analysis'] = self.analyze_config_data()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏
        self.analysis_results['migration_plan'] = self.generate_migration_plan()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        self.save_analysis_report()
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
        if self.client:
            self.client.close()
        
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        return self.analysis_results

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("üîç –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä MongoDB –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostOpus")
    print("=" * 60)
    
    # URL MongoDB
    mongo_url = "mongodb+srv://valstan:nitro2000@postopus.qjxr9.mongodb.net/postopus?retryWrites=true&w=majority"
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
        analyzer = MongoAnalyzer(mongo_url)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        results = analyzer.run_full_analysis()
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print("\nüìä –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê –ê–ù–ê–õ–ò–ó–ê:")
        print("-" * 40)
        
        collections = results.get('collections', {})
        print(f"üìã –ö–æ–ª–ª–µ–∫—Ü–∏–π –Ω–∞–π–¥–µ–Ω–æ: {len(collections)}")
        
        total_docs = sum(col['document_count'] for col in collections.values())
        print(f"üìÑ –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}")
        
        posts_analysis = results.get('posts_analysis', {})
        print(f"üìù –ü–æ—Å—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {posts_analysis.get('total_posts', 0)}")
        print(f"üìÇ –ö–æ–ª–ª–µ–∫—Ü–∏–π —Å –ø–æ—Å—Ç–∞–º–∏: {len(posts_analysis.get('collections_with_posts', []))}")
        
        config_analysis = results.get('config_analysis', {})
        groups = config_analysis.get('groups', {})
        print(f"üë• –ì—Ä—É–ø–ø –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {groups.get('count', 0)}")
        
        users = config_analysis.get('users', {})
        print(f"üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {users.get('count', 0)}")
        
        tasks = config_analysis.get('tasks', {})
        print(f"‚è∞ –ó–∞–¥–∞—á: {tasks.get('count', 0)}")
        
        print(f"\nüìÑ –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: mongo_analysis_report.json")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
